{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f91b4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akima done!!\n",
      "(推定スピーカー角度,推定マイク角度)[43, -34]\n"
     ]
    }
   ],
   "source": [
    "## coding: utf-8\n",
    "# データベースを作る\n",
    "# 計測用信号を読み込む\n",
    "# 測位する\n",
    "\n",
    "\n",
    "\n",
    "import wave\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "import scipy.signal as sg\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import scipy.interpolate as itpl\n",
    "import resampy\n",
    "\n",
    "def create_db():\n",
    "    sound_db = np.zeros(144*7*91*81).reshape(91,81,144*7)\n",
    "    sound_db[:,:,:] = np.nan\n",
    "    speaker_deg = 0\n",
    "    for j in range(0,4):\n",
    "        mic_deg = -40\n",
    "        for i in range(0,9):\n",
    "            #整形済み信号読み込み\n",
    "            signal = np.loadtxt('s'+str(speaker_deg)+'m'+str(mic_deg)+'.txt')\n",
    "            signal_fft = np.abs(fft(signal))\n",
    "            #chirps_up =  resampy.resample(signal_fft, 144, 144*2, filter='kaiser_fast')\n",
    "            sound_db[speaker_deg,mic_deg+40,:] = signal_fft\n",
    "            mic_deg += 10\n",
    "        speaker_deg +=30\n",
    "    #ここから秋間補間，マイク方位で補間した後スピーカ角度で補間\n",
    "    Akima = np.zeros(144*7*91*81).reshape(91,81,144*7)\n",
    "    Akima[:,:,:] = np.nan\n",
    "    #マイク方位で補間\n",
    "    count = 0\n",
    "    for i in range(0,4):\n",
    "        sound_db_d = pd.DataFrame(sound_db[count,:,:])\n",
    "        sound_db_d.astype('float64')\n",
    "        Akima[count,:,:] = sound_db_d.interpolate('akima')\n",
    "        count += 30\n",
    "    #スピーカ角度で補間\n",
    "    for j in range(0,81):\n",
    "        sound_db_d = pd.DataFrame(Akima[:,j,:])\n",
    "        sound_db_d.astype('float64')\n",
    "        Akima[:,j,:] = sound_db_d.interpolate('akima')\n",
    "    #Akima = pd_Zrf_d.interpolate('akima')\n",
    "    print('Akima done!!')\n",
    "    return Akima\n",
    "    \n",
    "# 残差平方和\n",
    "def rss(y, t):\n",
    "    f = np.sum((y-t).T*(y-t))\n",
    "    return f\n",
    "    \n",
    "    \n",
    "def estimate(db,file):\n",
    "    #データベースを読み込んで、残差平方和を計測\n",
    "    rss_db = np.zeros(91*81).reshape(91,81)\n",
    "    #print(rss_db)\n",
    "    for j in range(0,91):\n",
    "        for i in range(0,81):\n",
    "            rss_ans = rss(db[j,i],file[:])\n",
    "            rss_db[j,i] = rss_ans\n",
    "    estimate_mic_speaker = np.unravel_index(np.argmin(rss_db), rss_db.shape)\n",
    "    estimate_mic_speaker = list(estimate_mic_speaker)\n",
    "    estimate_mic_speaker[1] -= 40\n",
    "    print('(推定スピーカー角度,推定マイク角度)'+str(estimate_mic_speaker))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    db1 = create_db()\n",
    "    #整形済み測位信号読み込み\n",
    "    signal = np.loadtxt('s45m-25.txt')\n",
    "    chirps_up1 = np.abs(fft(signal))\n",
    "    #chirps_up1 =  resampy.resample(np.abs(fft(signal)), 144, 144*2, filter='kaiser_fast')\n",
    "    # 最小二乗法によって測位\n",
    "    estimate(db1,chirps_up1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270171b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "0,-25\n",
    "(推定スピーカー角度,推定マイク角度)[0, -28]\n",
    "45,-25\n",
    "(推定スピーカー角度,推定マイク角度)[43, -34]\n",
    "45,25\n",
    "(推定スピーカー角度,推定マイク角度)[43, 21]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
